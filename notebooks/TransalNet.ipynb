{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "diFoQb1zJpdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7SbqPX8PJefR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from os.path import join as pjoin\n",
        "import logging\n",
        "import math\n",
        "\n",
        "from torch.nn import CrossEntropyLoss, Dropout, Softmax, Linear, Conv2d, LayerNorm\n",
        "from torch.nn.modules.utils import _pair\n",
        "from scipy import ndimage"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "FYyCJQGAJ2Kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy dataset\n",
        "\n",
        "class SaliencyData(Dataset):\n",
        "  def __init__(self):\n",
        "\n",
        "    self.X = torch.randn(32 * 1, 3, 384, 288)\n",
        "    self.y = torch.randn(32 * 1, 1, 384, 288)\n",
        "    self.fix = torch.randn(32 * 1, 1, 384, 288)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    return torch.Tensor(self.X[idx]), torch.Tensor(self.y[idx]), torch.Tensor(self.fix[idx])"
      ],
      "metadata": {
        "id": "4sCwWuUxJn1k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SaliencyData()\n",
        "dataloader = DataLoader(dataset, batch_size=32, drop_last=True)"
      ],
      "metadata": {
        "id": "j2-B3XujuGvl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels, train_fix = next(iter(dataloader))\n",
        "print(f\"Train feature shape: {train_features.shape}\")\n",
        "print(f\"Train labels shape: {train_labels.shape}\")\n",
        "print(f\"Train fixations shape: {train_fix.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLNW12wvvZrT",
        "outputId": "daa9f681-07c7-4566-a4f9-8efb29b0482d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train feature shape: torch.Size([32, 3, 384, 288])\n",
            "Train labels shape: torch.Size([32, 1, 384, 288])\n",
            "Train fixations shape: torch.Size([32, 1, 384, 288])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocess\n",
        "\n",
        "def preprocess_img(img_dir, channels=3):\n",
        "\n",
        "    if channels == 1:\n",
        "        img = cv2.imread(img_dir, 0)\n",
        "    elif channels == 3:\n",
        "        img = cv2.imread(img_dir)\n",
        "\n",
        "    shape_r = 288\n",
        "    shape_c = 384\n",
        "    img_padded = np.ones((shape_r, shape_c, channels), dtype=np.uint8)\n",
        "    if channels == 1:\n",
        "        img_padded = np.zeros((shape_r, shape_c), dtype=np.uint8)\n",
        "    original_shape = img.shape\n",
        "    rows_rate = original_shape[0] / shape_r\n",
        "    cols_rate = original_shape[1] / shape_c\n",
        "    if rows_rate > cols_rate:\n",
        "        new_cols = (original_shape[1] * shape_r) // original_shape[0]\n",
        "        img = cv2.resize(img, (new_cols, shape_r))\n",
        "        if new_cols > shape_c:\n",
        "            new_cols = shape_c\n",
        "        img_padded[:,\n",
        "        ((img_padded.shape[1] - new_cols) // 2):((img_padded.shape[1] - new_cols) // 2 + new_cols)] = img\n",
        "    else:\n",
        "        new_rows = (original_shape[0] * shape_c) // original_shape[1]\n",
        "        img = cv2.resize(img, (shape_c, new_rows))\n",
        "\n",
        "        if new_rows > shape_r:\n",
        "            new_rows = shape_r\n",
        "        img_padded[((img_padded.shape[0] - new_rows) // 2):((img_padded.shape[0] - new_rows) // 2 + new_rows),\n",
        "        :] = img\n",
        "\n",
        "    return img_padded\n",
        "\n",
        "def postprocess_img(pred, org_dir):\n",
        "    pred = np.array(pred)\n",
        "    org = cv2.imread(org_dir, 0)\n",
        "    shape_r = org.shape[0]\n",
        "    shape_c = org.shape[1]\n",
        "    predictions_shape = pred.shape\n",
        "\n",
        "    rows_rate = shape_r / predictions_shape[0]\n",
        "    cols_rate = shape_c / predictions_shape[1]\n",
        "\n",
        "    if rows_rate > cols_rate:\n",
        "        new_cols = (predictions_shape[1] * shape_r) // predictions_shape[0]\n",
        "        pred = cv2.resize(pred, (new_cols, shape_r))\n",
        "        img = pred[:, ((pred.shape[1] - shape_c) // 2):((pred.shape[1] - shape_c) // 2 + shape_c)]\n",
        "    else:\n",
        "        new_rows = (predictions_shape[0] * shape_c) // predictions_shape[1]\n",
        "        pred = cv2.resize(pred, (shape_c, new_rows))\n",
        "        img = pred[((pred.shape[0] - shape_r) // 2):((pred.shape[0] - shape_r) // 2 + shape_r), :]\n",
        "\n",
        "    return img\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    \"\"\"Load dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, ids, stimuli_dir, saliency_dir, fixation_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.ids = ids\n",
        "        self.stimuli_dir = stimuli_dir\n",
        "        self.saliency_dir = saliency_dir\n",
        "        self.fixation_dir = fixation_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        im_path = self.stimuli_dir + self.ids.iloc[idx, 0]\n",
        "        image = Image.open(im_path).convert('RGB')\n",
        "        img = np.array(image) / 255.\n",
        "        img = np.transpose(img, (2, 0, 1))\n",
        "        img = torch.from_numpy(img)\n",
        "        # if self.transform:\n",
        "        #    img = self.transform(image)\n",
        "\n",
        "        smap_path = self.saliency_dir + self.ids.iloc[idx, 1]\n",
        "        saliency = Image.open(smap_path)\n",
        "\n",
        "        smap = np.expand_dims(np.array(saliency) / 255., axis=0)\n",
        "        smap = torch.from_numpy(smap)\n",
        "\n",
        "        fmap_path = self.fixation_dir + self.ids.iloc[idx, 2]\n",
        "        fixation = Image.open(fmap_path)\n",
        "\n",
        "        fmap = np.expand_dims(np.array(fixation) / 255., axis=0)\n",
        "        fmap = torch.from_numpy(fmap)\n",
        "\n",
        "        sample = {'image': img, 'saliency': smap, 'fixation': fmap}\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "uCo6vGM2LJa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "_tT5tPsYKb31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SaliencyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SaliencyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, preds, labels, loss_type='cc'):\n",
        "        losses = []\n",
        "        if loss_type == 'cc':\n",
        "            for i in range(labels.shape[0]): # labels.shape[0] is batch size\n",
        "                loss = loss_CC(preds[i],labels[i])\n",
        "                losses.append(loss)\n",
        "\n",
        "        elif loss_type == 'kldiv':\n",
        "            for i in range(labels.shape[0]):\n",
        "                loss = loss_KLdiv(preds[i],labels[i])\n",
        "                losses.append(loss)\n",
        "\n",
        "        elif loss_type == 'sim':\n",
        "            for i in range(labels.shape[0]):\n",
        "                loss = loss_similarity(preds[i],labels[i])\n",
        "                losses.append(loss)\n",
        "\n",
        "        elif loss_type == 'nss':\n",
        "            for i in range(labels.shape[0]):\n",
        "                loss = loss_NSS(preds[i],labels[i])\n",
        "                losses.append(loss)\n",
        "            \n",
        "        return torch.stack(losses).mean(dim=0, keepdim=True)\n",
        "        \n",
        "        \n",
        "def loss_KLdiv(pred_map, gt_map):\n",
        "    eps = 2.2204e-16\n",
        "    pred_map = pred_map/torch.sum(pred_map)\n",
        "    gt_map = gt_map/torch.sum(gt_map)\n",
        "    div = torch.sum(torch.mul(gt_map, torch.log(eps + torch.div(gt_map,pred_map+eps))))\n",
        "    return div \n",
        "        \n",
        "    \n",
        "def loss_CC(pred_map,gt_map):\n",
        "    gt_map_ = (gt_map - torch.mean(gt_map))\n",
        "    pred_map_ = (pred_map - torch.mean(pred_map))\n",
        "    cc = torch.sum(torch.mul(gt_map_,pred_map_))/torch.sqrt(torch.sum(torch.mul(gt_map_,gt_map_))*torch.sum(torch.mul(pred_map_,pred_map_)))\n",
        "    return cc\n",
        "\n",
        "\n",
        "def loss_similarity(pred_map,gt_map):\n",
        "    gt_map = (gt_map - torch.min(gt_map))/(torch.max(gt_map)-torch.min(gt_map))\n",
        "    gt_map = gt_map/torch.sum(gt_map)\n",
        "    \n",
        "    pred_map = (pred_map - torch.min(pred_map))/(torch.max(pred_map)-torch.min(pred_map))\n",
        "    pred_map = pred_map/torch.sum(pred_map)\n",
        "    \n",
        "    diff = torch.min(gt_map,pred_map)\n",
        "    score = torch.sum(diff)\n",
        "    \n",
        "    return score\n",
        "    \n",
        "    \n",
        "def loss_NSS(pred_map,fix_map):\n",
        "    '''ground truth here is fixation map'''\n",
        "\n",
        "    pred_map_ = (pred_map - torch.mean(pred_map))/torch.std(pred_map)\n",
        "    mask = fix_map.gt(0)\n",
        "    score = torch.mean(torch.masked_select(pred_map_, mask))\n",
        "    return score"
      ],
      "metadata": {
        "id": "JMhigkuHKcnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Densenet utils\n",
        "\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "from torch import Tensor\n",
        "from torch.jit.annotations import List\n",
        "import torch.utils.checkpoint as cp\n",
        "\n",
        "__all__ = ['DenseNet', 'densenet121', 'densenet169', 'densenet201', 'densenet161']\n",
        "\n",
        "model_urls = {\n",
        "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Module):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                                           growth_rate, kernel_size=1, stride=1,\n",
        "                                           bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                                           kernel_size=3, stride=1, padding=1,\n",
        "                                           bias=False)),\n",
        "        self.drop_rate = float(drop_rate)\n",
        "        self.memory_efficient = memory_efficient\n",
        "\n",
        "    def bn_function(self, inputs):\n",
        "        # type: (List[Tensor]) -> Tensor\n",
        "        concated_features = torch.cat(inputs, 1)\n",
        "        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\n",
        "        return bottleneck_output\n",
        "\n",
        "    # todo: rewrite when torchscript supports any\n",
        "    def any_requires_grad(self, input):\n",
        "        # type: (List[Tensor]) -> bool\n",
        "        for tensor in input:\n",
        "            if tensor.requires_grad:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    @torch.jit.unused  # noqa: T484\n",
        "    def call_checkpoint_bottleneck(self, input):\n",
        "        # type: (List[Tensor]) -> Tensor\n",
        "        def closure(*inputs):\n",
        "            return self.bn_function(inputs)\n",
        "\n",
        "        return cp.checkpoint(closure, *input)\n",
        "\n",
        "    @torch.jit._overload_method  # noqa: F811\n",
        "    def forward(self, input):\n",
        "        # type: (List[Tensor]) -> (Tensor)\n",
        "        pass\n",
        "\n",
        "    @torch.jit._overload_method  # noqa: F811\n",
        "    def forward(self, input):\n",
        "        # type: (Tensor) -> (Tensor)\n",
        "        pass\n",
        "\n",
        "    # torchscript does not yet support *args, so we overload method\n",
        "    # allowing it to take either a List[Tensor] or single Tensor\n",
        "    def forward(self, input):  # noqa: F811\n",
        "        if isinstance(input, Tensor):\n",
        "            prev_features = [input]\n",
        "        else:\n",
        "            prev_features = input\n",
        "\n",
        "        if self.memory_efficient and self.any_requires_grad(prev_features):\n",
        "            if torch.jit.is_scripting():\n",
        "                raise Exception(\"Memory Efficient not supported in JIT\")\n",
        "\n",
        "            bottleneck_output = self.call_checkpoint_bottleneck(prev_features)\n",
        "        else:\n",
        "            bottleneck_output = self.bn_function(prev_features)\n",
        "\n",
        "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
        "                                     training=self.training)\n",
        "        return new_features\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.ModuleDict):\n",
        "    _version = 2\n",
        "\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate, memory_efficient=False):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(\n",
        "                num_input_features + i * growth_rate,\n",
        "                growth_rate=growth_rate,\n",
        "                bn_size=bn_size,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient,\n",
        "            )\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "    def forward(self, init_features):\n",
        "        features = [init_features]\n",
        "        for name, layer in self.items():\n",
        "            new_features = layer(features)\n",
        "            features.append(new_features)\n",
        "        return torch.cat(features, 1)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000, memory_efficient=False):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\n",
        "                                padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(\n",
        "                num_layers=num_layers,\n",
        "                num_input_features=num_features,\n",
        "                bn_size=bn_size,\n",
        "                growth_rate=growth_rate,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient\n",
        "            )\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features,\n",
        "                                    num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def _load_state_dict(model, model_url, progress, flag):\n",
        "    # '.'s are no longer allowed in module names, but previous _DenseLayer\n",
        "    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "    # They are also in the checkpoints in model_urls. This pattern is used\n",
        "    # to find such keys.\n",
        "    pattern = re.compile(\n",
        "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "    if flag == \"densenet161\":\n",
        "        state_dict = torch.load(r'pretrained_models/densenet161-8d451a50.pth')\n",
        "    else:\n",
        "        state_dict = load_state_dict_from_url(model_url, progress=progress)\n",
        "    for key in list(state_dict.keys()):\n",
        "        res = pattern.match(key)\n",
        "        if res:\n",
        "            new_key = res.group(1) + res.group(2)\n",
        "            state_dict[new_key] = state_dict[key]\n",
        "            del state_dict[key]\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "\n",
        "def _densenet(arch, growth_rate, block_config, num_init_features, pretrained, progress,\n",
        "              **kwargs):\n",
        "    model = DenseNet(growth_rate, block_config, num_init_features, **kwargs)\n",
        "    if pretrained:\n",
        "        if arch == 'densenet161':\n",
        "            _load_state_dict(model, model_urls[arch], progress, 'densenet161')\n",
        "        else:\n",
        "            _load_state_dict(model, model_urls[arch], progress, 0)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet121(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet('densenet121', 32, (6, 12, 24, 16), 64, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def densenet161(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet('densenet161', 48, (6, 12, 36, 24), 96, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet('densenet169', 32, (6, 12, 32, 32), 64, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet('densenet201', 32, (6, 12, 48, 32), 64, pretrained, progress,\n",
        "                     **kwargs)"
      ],
      "metadata": {
        "id": "hr8_ctS1MjcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trans based on DenseNet"
      ],
      "metadata": {
        "id": "PQax4F-dMBZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "ACT2FN = {\"gelu\": torch.nn.functional.gelu, \"relu\": torch.nn.functional.relu}\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_attention_heads = config[\"num_heads\"]  # 12\n",
        "        self.attention_head_size = int(config['hidden_size'] / self.num_attention_heads)    # 42\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size    # 12*42=504\n",
        "\n",
        "        self.query = Linear(config['hidden_size'], self.all_head_size)  # (512, 504)\n",
        "        self.key = Linear(config['hidden_size'], self.all_head_size)\n",
        "        self.value = Linear(config['hidden_size'], self.all_head_size)\n",
        "\n",
        "        # self.out = Linear(config['hidden_size'], config['hidden_size'])\n",
        "        self.out = Linear(self.all_head_size, config['hidden_size'])\n",
        "        self.attn_dropout = Dropout(config[\"attention_dropout_rate\"])\n",
        "        self.proj_dropout = Dropout(config[\"attention_dropout_rate\"])\n",
        "\n",
        "        self.softmax = Softmax(dim=-1)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        attention_probs = self.softmax(attention_scores)\n",
        "        attention_probs = self.attn_dropout(attention_probs)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "        attention_output = self.out(context_layer)\n",
        "        attention_output = self.proj_dropout(attention_output)\n",
        "        return attention_output\n",
        "\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Mlp, self).__init__()\n",
        "        self.fc1 = Linear(config['hidden_size'], config[\"mlp_dim\"])\n",
        "        self.fc2 = Linear(config[\"mlp_dim\"], config['hidden_size'])\n",
        "        self.act_fn = ACT2FN[\"gelu\"]\n",
        "        self.dropout = Dropout(config[\"dropout_rate\"])\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.normal_(self.fc1.bias, std=1e-6)\n",
        "        nn.init.normal_(self.fc2.bias, std=1e-6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Block, self).__init__()\n",
        "        self.flag = config['num_heads']\n",
        "        self.hidden_size = config['hidden_size']\n",
        "        self.ffn_norm = LayerNorm(config['hidden_size'], eps=1e-6)\n",
        "        self.ffn = Mlp(config)\n",
        "        self.attn = Attention(config)\n",
        "        self.attention_norm = LayerNorm(config['hidden_size'], eps=1e-6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "\n",
        "        x = self.attention_norm(x)\n",
        "        x = self.attn(x)\n",
        "        x = x + h\n",
        "\n",
        "        h = x\n",
        "        x = self.ffn_norm(x)\n",
        "        x = self.ffn(x)\n",
        "        x = x + h\n",
        "        return x\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layer = nn.ModuleList()\n",
        "        self.encoder_norm = LayerNorm(config['hidden_size'], eps=1e-6)\n",
        "        for _ in range(config[\"num_layers\"]):\n",
        "            layer = Block(config)\n",
        "            self.layer.append(copy.deepcopy(layer))\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        for layer_block in self.layer:\n",
        "            hidden_states = layer_block(hidden_states)\n",
        "        encoded = self.encoder_norm(hidden_states)\n",
        "\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "vg6ek7k9MZpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denset = densenet161(pretrained=False)"
      ],
      "metadata": {
        "id": "fGKkrqIEOADS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg1 = {\n",
        "\"hidden_size\" : 768,\n",
        "\"mlp_dim\" : 768*4,\n",
        "\"num_heads\" : 12,\n",
        "\"num_layers\" : 2,\n",
        "\"attention_dropout_rate\" : 0,\n",
        "\"dropout_rate\" : 0.0,\n",
        "}\n",
        "\n",
        "cfg2 = {\n",
        "\"hidden_size\" : 768,\n",
        "\"mlp_dim\" : 768*4,\n",
        "\"num_heads\" : 12,\n",
        "\"num_layers\" : 2,\n",
        "\"attention_dropout_rate\" : 0,\n",
        "\"dropout_rate\" : 0.0,\n",
        "}\n",
        "\n",
        "cfg3 = {\n",
        "\"hidden_size\" : 512,\n",
        "\"mlp_dim\" : 512*4,\n",
        "\"num_heads\" : 8,\n",
        "\"num_layers\" : 2,\n",
        "\"attention_dropout_rate\" : 0,\n",
        "\"dropout_rate\" : 0.0,\n",
        "}\n",
        "\n",
        "\n",
        "class TranSalNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TranSalNet, self).__init__()\n",
        "        self.encoder = _Encoder()\n",
        "        self.decoder = _Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class _Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(_Encoder, self).__init__()\n",
        "        base_model = densenet161(pretrained=False)\n",
        "        base_layers = list(base_model.children())[0][:-1]\n",
        "        self.encoder = nn.ModuleList(base_layers).eval()\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        for ii,layer in enumerate(self.encoder):\n",
        "            x = layer(x)\n",
        "            if ii in {6, 8, 10}:\n",
        "                outputs.append(x)\n",
        "        return outputs\n",
        "\n",
        "class _Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(_Decoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv2 = nn.Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv3 = nn.Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv4 = nn.Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv5 = nn.Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv6 = nn.Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv7 = nn.Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        self.TransEncoder1 = TransEncoder(in_channels=2208, spatial_size=9*12, cfg=cfg1)\n",
        "        self.TransEncoder2 = TransEncoder(in_channels=2112, spatial_size=18*24, cfg=cfg2)\n",
        "        self.TransEncoder3 = TransEncoder(in_channels=768, spatial_size=36*48, cfg=cfg3)\n",
        "\n",
        "        self.add = torch.add\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x3, x4, x5 = x\n",
        "\n",
        "        x5 = self.TransEncoder1(x5)\n",
        "        x5 = self.conv1(x5)\n",
        "        x5 = self.batchnorm1(x5)\n",
        "        x5 = self.relu(x5)\n",
        "        x5 = self.upsample(x5)\n",
        "\n",
        "        x4_a = self.TransEncoder2(x4)\n",
        "        x4 = x5 * x4_a\n",
        "        x4 = self.relu(x4)\n",
        "        x4 = self.conv2(x4)\n",
        "        x4 = self.batchnorm2(x4)\n",
        "        x4 = self.relu(x4)\n",
        "        x4 = self.upsample(x4)\n",
        "\n",
        "        x3_a = self.TransEncoder3(x3)\n",
        "        x3 = x4 * x3_a\n",
        "        x3 = self.relu(x3)\n",
        "        x3 = self.conv3(x3)\n",
        "        x3 = self.batchnorm3(x3)\n",
        "        x3 = self.relu(x3)\n",
        "        x3 = self.upsample(x3)\n",
        "\n",
        "        x2 = self.conv4(x3)\n",
        "        x2 = self.batchnorm4(x2)\n",
        "        x2 = self.relu(x2)\n",
        "        x2 = self.upsample(x2)\n",
        "        x2 = self.conv5(x2)\n",
        "        x2 = self.batchnorm5(x2)\n",
        "        x2 = self.relu(x2)\n",
        "\n",
        "        x1 = self.upsample(x2)\n",
        "        x1 = self.conv6(x1)\n",
        "        x1 = self.batchnorm6(x1)\n",
        "        x1 = self.relu(x1)\n",
        "        x1 = self.conv7(x1)\n",
        "        x = self.sigmoid(x1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, spatial_size, cfg):\n",
        "        super(TransEncoder, self).__init__()\n",
        "\n",
        "        self.patch_embeddings = nn.Conv2d(in_channels=in_channels,\n",
        "                                          out_channels=cfg['hidden_size'],\n",
        "                                          kernel_size=1,\n",
        "                                          stride=1)\n",
        "        self.position_embeddings = nn.Parameter(torch.zeros(1, spatial_size, cfg['hidden_size']))\n",
        "\n",
        "        self.transformer_encoder = Encoder(cfg)\n",
        "\n",
        "    def forward(self, x):\n",
        "        a, b = x.shape[2], x.shape[3]\n",
        "        x = self.patch_embeddings(x)\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(-1, -2)\n",
        "\n",
        "        embeddings = x + self.position_embeddings\n",
        "        x = self.transformer_encoder(embeddings)\n",
        "        B, n_patch, hidden = x.shape\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = x.contiguous().view(B, hidden, a, b)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "VCxD5aSAK9rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  TranSalNet()"
      ],
      "metadata": {
        "id": "etLig95vQOOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0yOlSRCQc97",
        "outputId": "32e98eea-caaf-4b50-b43f-e619efdc6ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TranSalNet(\n",
              "  (encoder): _Encoder(\n",
              "    (encoder): ModuleList(\n",
              "      (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (4): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (5): _Transition(\n",
              "        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "      (6): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer7): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer8): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer9): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer10): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer11): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer12): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (7): _Transition(\n",
              "        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "      (8): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer7): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer8): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer9): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer10): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer11): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer12): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer13): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer14): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer15): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer16): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer17): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer18): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer19): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer20): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer21): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer22): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer23): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer24): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer25): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer26): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer27): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer28): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer29): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer30): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer31): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer32): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer33): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer34): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer35): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer36): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (9): _Transition(\n",
              "        (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      )\n",
              "      (10): _DenseBlock(\n",
              "        (denselayer1): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer2): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer3): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer4): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer5): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer6): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer7): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer8): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer9): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer10): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer11): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer12): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer13): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer14): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer15): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer16): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer17): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer18): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer19): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer20): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer21): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer22): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer23): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (denselayer24): _DenseLayer(\n",
              "          (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu1): ReLU(inplace=True)\n",
              "          (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu2): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): _Decoder(\n",
              "    (conv1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv5): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv7): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (batchnorm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (batchnorm6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (TransEncoder1): TransEncoder(\n",
              "      (patch_embeddings): Conv2d(2208, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (transformer_encoder): Encoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-1): 2 x Block(\n",
              "            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "            (ffn): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (attn): Attention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (attn_dropout): Dropout(p=0, inplace=False)\n",
              "              (proj_dropout): Dropout(p=0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (encoder_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (TransEncoder2): TransEncoder(\n",
              "      (patch_embeddings): Conv2d(2112, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (transformer_encoder): Encoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-1): 2 x Block(\n",
              "            (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "            (ffn): Mlp(\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (attn): Attention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (attn_dropout): Dropout(p=0, inplace=False)\n",
              "              (proj_dropout): Dropout(p=0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (encoder_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (TransEncoder3): TransEncoder(\n",
              "      (patch_embeddings): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (transformer_encoder): Encoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-1): 2 x Block(\n",
              "            (ffn_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (ffn): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (attn): Attention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (attn_dropout): Dropout(p=0, inplace=False)\n",
              "              (proj_dropout): Dropout(p=0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (attention_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (encoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "onM3ARCKw9I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TranSalNet()\n",
        "model = model.to(device)\n",
        "dataset_size = 20"
      ],
      "metadata": {
        "id": "-_dQ9RWVQewf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=1e-5)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "loss_fn = SaliencyLoss()\n",
        "\n",
        "'''Training'''\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "num_epochs =30\n",
        "best_loss = 100\n",
        "for k,v in model.named_parameters():\n",
        "    print('{}: {}'.format(k, v.requires_grad))\n",
        "\n",
        "                 \n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()  # Set model to training mode\n",
        "        else:\n",
        "            model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Iterate over data\n",
        "        for i_batch, sample_batched in tqdm(enumerate(dataloader)):\n",
        "            stimuli, smap, fmap = sample_batched\n",
        "            stimuli, smap, fmap = stimuli.to(device), smap.to(device), fmap.to(device)\n",
        "            \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward propogation\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(stimuli)\n",
        "                \n",
        "\n",
        "                loss = -2*loss_fn(outputs,smap,loss_type='cc')\\\n",
        "                        -1*loss_fn(outputs,smap,loss_type='sim')+\\\n",
        "                        10*loss_fn(outputs,smap,loss_type='kldiv')-1*loss_fn(outputs,fmap,loss_type='nss')\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * stimuli.size(0)\n",
        "\n",
        "        if phase == 'train':\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / dataset_size\n",
        "                \n",
        "        print('{} Loss: {:.4f}'.format(\n",
        "            phase, epoch_loss))\n",
        "        \n",
        "        \n",
        "        if phase == 'val' and epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            counter = 0\n",
        "        elif phase == 'val' and epoch_loss >= best_loss:\n",
        "            counter += 1\n",
        "            if counter ==5:\n",
        "                print('early stop!')\n",
        "                break\n",
        "    else:\n",
        "        continue\n",
        "    break\n",
        "    print()\n",
        "\n",
        "print('Best val loss: {:4f}'.format(best_loss))\n",
        "model.load_state_dict(best_model_wts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "2twawL_pxBnx",
        "outputId": "67f40031-71ee-4541-d9a5-2b3617b313f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1ac798f826a7>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m'''Training'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbest_model_wts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     )\n\u001b[1;32m    117\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_quantized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0;31m# quantizer_params can be different type based on torch attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m_deepcopy\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;31m# For internal use only, to avoid deprecation warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_wrapped_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sizeof__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"\"\"Returns a copy of this storage\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.75 GiB total capacity; 13.61 GiB already allocated; 832.00 KiB free; 13.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVtW_deRyh-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}