{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a70ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.special import logsumexp\n",
    "from scipy.misc import face\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0983f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec44f5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-1a75e7ae1ec2>:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  image_tensor = torch.tensor([image.transpose(2, 0, 1)]).to(DEVICE)\n"
     ]
    }
   ],
   "source": [
    "image = face()\n",
    "# load precomputed centerbias log density (from MIT1003) over a 1024x1024 image\n",
    "# you can download the centerbias from https://github.com/matthias-k/DeepGaze/releases/download/v1.0.0/centerbias_mit1003.npy\n",
    "# alternatively, you can use a uniform centerbias via `centerbias_template = np.zeros((1024, 1024))`.\n",
    "centerbias_template = np.load('centerbias_mit1003.npy')\n",
    "# rescale to match image size\n",
    "centerbias = zoom(centerbias_template, (image.shape[0]/centerbias_template.shape[0], image.shape[1]/centerbias_template.shape[1]), order=0, mode='nearest')\n",
    "# renormalize log density\n",
    "centerbias -= logsumexp(centerbias)\n",
    "\n",
    "image_tensor = torch.tensor([image.transpose(2, 0, 1)]).to(DEVICE)\n",
    "centerbias_tensor = torch.tensor([centerbias]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef474d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4332cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .layers import GaussianFilterNd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d23dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter_1d(tensor, dim, sigma, truncate=4, kernel_size=None, padding_mode='replicate', padding_value=0.0):\n",
    "    sigma = torch.as_tensor(sigma, device=tensor.device, dtype=tensor.dtype)\n",
    "\n",
    "    if kernel_size is not None:\n",
    "        kernel_size = torch.as_tensor(kernel_size, device=tensor.device, dtype=torch.int64)\n",
    "    else:\n",
    "        kernel_size = torch.as_tensor(2 * torch.ceil(truncate * sigma) + 1, device=tensor.device, dtype=torch.int64)\n",
    "\n",
    "    kernel_size = kernel_size.detach()\n",
    "\n",
    "    kernel_size_int = kernel_size.detach().cpu().numpy()\n",
    "\n",
    "    mean = (torch.as_tensor(kernel_size, dtype=tensor.dtype) - 1) / 2\n",
    "\n",
    "    grid = torch.arange(kernel_size, device=tensor.device) - mean\n",
    "\n",
    "    kernel_shape = (1, 1, kernel_size)\n",
    "    grid = grid.view(kernel_shape)\n",
    "\n",
    "    grid = grid.detach()\n",
    "\n",
    "    source_shape = tensor.shape\n",
    "\n",
    "    tensor = torch.movedim(tensor, dim, len(source_shape)-1)\n",
    "    dim_last_shape = tensor.shape\n",
    "    assert tensor.shape[-1] == source_shape[dim]\n",
    "\n",
    "    # we need reshape instead of view for batches like B x C x H x W\n",
    "    tensor = tensor.reshape(-1, 1, source_shape[dim])\n",
    "\n",
    "    padding = (math.ceil((kernel_size_int - 1) / 2), math.ceil((kernel_size_int - 1) / 2))\n",
    "    tensor_ = F.pad(tensor, padding, padding_mode, padding_value)\n",
    "\n",
    "    # create gaussian kernel from grid using current sigma\n",
    "    kernel = torch.exp(-0.5 * (grid / sigma) ** 2)\n",
    "    kernel = kernel / kernel.sum()\n",
    "\n",
    "    # convolve input with gaussian kernel\n",
    "    tensor_ = F.conv1d(tensor_, kernel)\n",
    "    tensor_ = tensor_.view(dim_last_shape)\n",
    "    tensor_ = torch.movedim(tensor_, len(source_shape)-1, dim)\n",
    "\n",
    "    assert tensor_.shape == source_shape\n",
    "\n",
    "    return tensor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92433f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianFilterNd(nn.Module):\n",
    "    \"\"\"A differentiable gaussian filter\"\"\"\n",
    "\n",
    "    def __init__(self, dims, sigma, truncate=4, kernel_size=None, padding_mode='replicate', padding_value=0.0,\n",
    "                 trainable=False):\n",
    "        \"\"\"Creates a 1d gaussian filter\n",
    "        Args:\n",
    "            dims ([int]): the dimensions to which the gaussian filter is applied. Negative values won't work\n",
    "            sigma (float): standard deviation of the gaussian filter (blur size)\n",
    "            input_dims (int, optional): number of input dimensions ignoring batch and channel dimension,\n",
    "                i.e. use input_dims=2 for images (default: 2).\n",
    "            truncate (float, optional): truncate the filter at this many standard deviations (default: 4.0).\n",
    "                This has no effect if the `kernel_size` is explicitely set\n",
    "            kernel_size (int): size of the gaussian kernel convolved with the input\n",
    "            padding_mode (string, optional): Padding mode implemented by `torch.nn.functional.pad`.\n",
    "            padding_value (string, optional): Value used for constant padding.\n",
    "        \"\"\"\n",
    "        # IDEA determine input_dims dynamically for every input\n",
    "        super(GaussianFilterNd, self).__init__()\n",
    "\n",
    "        self.dims = dims\n",
    "        self.sigma = nn.Parameter(torch.tensor(sigma, dtype=torch.float32), requires_grad=trainable)  # default: no optimization\n",
    "        self.truncate = truncate\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        # setup padding\n",
    "        self.padding_mode = padding_mode\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"Applies the gaussian filter to the given tensor\"\"\"\n",
    "        for dim in self.dims:\n",
    "            tensor = gaussian_filter_1d(\n",
    "                tensor,\n",
    "                dim=dim,\n",
    "                sigma=self.sigma,\n",
    "                truncate=self.truncate,\n",
    "                kernel_size=self.kernel_size,\n",
    "                padding_mode=self.padding_mode,\n",
    "                padding_value=self.padding_value,\n",
    "            )\n",
    "\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa3d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(torch.nn.Module):\n",
    "    def __init__(self, features, targets):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        #print(\"Targets are {}\".format(targets))\n",
    "        self.outputs = {}\n",
    "\n",
    "        for target in targets:\n",
    "            layer = dict([*self.features.named_modules()])[target]\n",
    "            layer.register_forward_hook(self.save_outputs_hook(target))\n",
    "\n",
    "    def save_outputs_hook(self, layer_id: str):\n",
    "        def fn(_, __, output):\n",
    "            self.outputs[layer_id] = output.clone()\n",
    "        return fn\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        self.outputs.clear()\n",
    "        self.features(x)\n",
    "        return [self.outputs[target] for target in self.targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7258b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(tensor, size):\n",
    "    tensor_size = torch.tensor(tensor.shape[2:]).type(torch.float32)\n",
    "    target_size = torch.tensor(size).type(torch.float32)\n",
    "    factors = torch.ceil(target_size / tensor_size)\n",
    "    factor = torch.max(factors).type(torch.int64).to(tensor.device)\n",
    "    assert factor >= 1\n",
    "\n",
    "    tensor = torch.repeat_interleave(tensor, factor, dim=2)\n",
    "    tensor = torch.repeat_interleave(tensor, factor, dim=3)\n",
    "\n",
    "    tensor = tensor[:, :, :size[0], :size[1]]\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30718644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Finalizer(nn.Module):\n",
    "    \"\"\"Transforms a readout into a gaze prediction\n",
    "    A readout network returns a single, spatial map of probable gaze locations.\n",
    "    This module bundles the common processing steps necessary to transform this into\n",
    "    the predicted gaze distribution:\n",
    "     - resizing to the stimulus size\n",
    "     - smoothing of the prediction using a gaussian filter\n",
    "     - removing of channel and time dimension\n",
    "     - weighted addition of the center bias\n",
    "     - normalization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sigma,\n",
    "        kernel_size=None,\n",
    "        learn_sigma=False,\n",
    "        center_bias_weight=1.0,\n",
    "        learn_center_bias_weight=True,\n",
    "        saliency_map_factor=4,\n",
    "    ):\n",
    "        \"\"\"Creates a new finalizer\n",
    "        Args:\n",
    "            size (tuple): target size for the predictions\n",
    "            sigma (float): standard deviation of the gaussian kernel used for smoothing\n",
    "            kernel_size (int, optional): size of the gaussian kernel\n",
    "            learn_sigma (bool, optional): If True, the standard deviation of the gaussian kernel will\n",
    "                be learned (default: False)\n",
    "            center_bias (string or tensor): the center bias\n",
    "            center_bias_weight (float, optional): initial weight of the center bias\n",
    "            learn_center_bias_weight (bool, optional): If True, the center bias weight will be\n",
    "                learned (default: True)\n",
    "        \"\"\"\n",
    "        super(Finalizer, self).__init__()\n",
    "\n",
    "        self.saliency_map_factor = saliency_map_factor\n",
    "\n",
    "        self.gauss = GaussianFilterNd([2, 3], sigma, truncate=3, trainable=learn_sigma)\n",
    "        self.center_bias_weight = nn.Parameter(torch.Tensor([center_bias_weight]), requires_grad=learn_center_bias_weight)\n",
    "\n",
    "    def forward(self, readout, centerbias):\n",
    "        \"\"\"Applies the finalization steps to the given readout\"\"\"\n",
    "\n",
    "        downscaled_centerbias = F.interpolate(\n",
    "            centerbias.view(centerbias.shape[0], 1, centerbias.shape[1], centerbias.shape[2]),\n",
    "            scale_factor=1 / self.saliency_map_factor,\n",
    "            recompute_scale_factor=False,\n",
    "        )[:, 0, :, :]\n",
    "\n",
    "        out = F.interpolate(\n",
    "            readout,\n",
    "            size=[downscaled_centerbias.shape[1], downscaled_centerbias.shape[2]]\n",
    "        )\n",
    "\n",
    "        # apply gaussian filter\n",
    "        out = self.gauss(out)\n",
    "\n",
    "        # remove channel dimension\n",
    "        out = out[:, 0, :, :]\n",
    "\n",
    "        # add to center bias\n",
    "        out = out + self.center_bias_weight * downscaled_centerbias\n",
    "\n",
    "        out = F.interpolate(out[:, np.newaxis, :, :], size=[centerbias.shape[1], centerbias.shape[2]])[:, 0, :, :]\n",
    "\n",
    "        # normalize\n",
    "        out = out - out.logsumexp(dim=(1, 2), keepdim=True)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5e9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGazeII(torch.nn.Module):\n",
    "    def __init__(self, features, readout_network, downsample=2, readout_factor=16, saliency_map_factor=2, initial_sigma=8.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.readout_factor = readout_factor\n",
    "        self.saliency_map_factor = saliency_map_factor\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.features.eval()\n",
    "\n",
    "        self.readout_network = readout_network\n",
    "        self.finalizer = Finalizer(\n",
    "            sigma=initial_sigma,\n",
    "            learn_sigma=True,\n",
    "            saliency_map_factor=self.saliency_map_factor,\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x, centerbias):\n",
    "        orig_shape = x.shape\n",
    "        x = F.interpolate(\n",
    "            x,\n",
    "            scale_factor=1 / self.downsample,\n",
    "            recompute_scale_factor=False,\n",
    "        )\n",
    "        x = self.features(x)\n",
    "\n",
    "        readout_shape = [math.ceil(orig_shape[2] / self.downsample / self.readout_factor), math.ceil(orig_shape[3] / self.downsample / self.readout_factor)]\n",
    "        x = [F.interpolate(item, readout_shape) for item in x]\n",
    "\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = self.readout_network(x)\n",
    "        x = self.finalizer(x, centerbias)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        self.features.eval()\n",
    "        self.readout_network.train(mode=mode)\n",
    "        self.finalizer.train(mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ec3031",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OrderedDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m readout_network \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[43mOrderedDict\u001b[49m([\n\u001b[0;32m      2\u001b[0m             (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv0\u001b[39m\u001b[38;5;124m'\u001b[39m, nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[0;32m      3\u001b[0m         ]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OrderedDict' is not defined"
     ]
    }
   ],
   "source": [
    "readout_network = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(512, 1, (1, 1), bias=False)),\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "059d1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2  = DeepGazeII(model[1].conv1, readout_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "223cd143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGazeII(\n",
       "  (features): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (readout_network): Sequential(\n",
       "    (conv0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (finalizer): Finalizer(\n",
       "    (gauss): GaussianFilterNd()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1b943df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = DeepGazeII(model_feature, readout_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ae0e8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGazeII(\n",
       "  (features): FeatureExtractor(\n",
       "    (features): RGBResNet34(\n",
       "      (0): Normalizer()\n",
       "      (1): ResNet(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (4): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (5): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (readout_network): Sequential(\n",
       "    (conv0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (finalizer): Finalizer(\n",
       "    (gauss): GaussianFilterNd()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a521b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "centerbias_template = np.load('centerbias_mit1003.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb520e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "centerbias = zoom(centerbias_template, (224/centerbias_template.shape[0], 224/centerbias_template.shape[1]), order=0, mode='nearest')\n",
    "# renormalize log density\n",
    "centerbias -= logsumexp(centerbias)\n",
    "\n",
    "image_tensor = torch.tensor([image.transpose(2, 0, 1)]).to(DEVICE)\n",
    "centerbias_tensor = torch.tensor([centerbias]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed36fb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centerbias_tensor.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bd7992a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepGazeII(\n",
       "  (features): FeatureExtractor(\n",
       "    (features): RGBResNet34(\n",
       "      (0): Normalizer()\n",
       "      (1): ResNet(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (4): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (5): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (readout_network): Sequential(\n",
       "    (conv0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (finalizer): Finalizer(\n",
       "    (gauss): GaussianFilterNd()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2ee7fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images = np.random.rand(3,224, 224)\n",
    "# torch_image = torch.from_numpy(images)\n",
    "torch_image = torch.rand(1,3, 224,224, dtype=torch.float)\n",
    "torch_image.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c630a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model3(torch_image.to('cuda'), centerbias_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d1c4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5eaca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ceec0bd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rand(): argument 'size' must be tuple of ints, but found element of type tuple at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenterbias\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py:60\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     57\u001b[0m     input_size \u001b[38;5;241m=\u001b[39m [input_size]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# batch_size of 2 for batchnorm\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m x \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m*\u001b[39min_size)\u001b[38;5;241m.\u001b[39mtype(dtype) \u001b[38;5;28;01mfor\u001b[39;00m in_size \u001b[38;5;129;01min\u001b[39;00m input_size]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# print(type(x[0]))\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# create properties\u001b[39;00m\n\u001b[0;32m     64\u001b[0m summary \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py:60\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m     input_size \u001b[38;5;241m=\u001b[39m [input_size]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# batch_size of 2 for batchnorm\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m x \u001b[38;5;241m=\u001b[39m [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(dtype) \u001b[38;5;28;01mfor\u001b[39;00m in_size \u001b[38;5;129;01min\u001b[39;00m input_size]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# print(type(x[0]))\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# create properties\u001b[39;00m\n\u001b[0;32m     64\u001b[0m summary \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "\u001b[1;31mTypeError\u001b[0m: rand(): argument 'size' must be tuple of ints, but found element of type tuple at pos 2"
     ]
    }
   ],
   "source": [
    "summary(model3, ((224, 224, 3), centerbias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5b0eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(log_density, fixation_mask, weights=None):\n",
    "    #if weights is None:\n",
    "    #    weights = torch.ones(log_density.shape[0])\n",
    "\n",
    "    weights = len(weights) * weights.view(-1, 1, 1) / weights.sum()\n",
    "\n",
    "    if isinstance(fixation_mask, torch.sparse.IntTensor):\n",
    "        dense_mask = fixation_mask.to_dense()\n",
    "    else:\n",
    "        dense_mask = fixation_mask\n",
    "    fixation_count = dense_mask.sum(dim=(-1, -2), keepdim=True)\n",
    "    ll = torch.mean(\n",
    "        weights * torch.sum(log_density * dense_mask, dim=(-1, -2), keepdim=True) / fixation_count\n",
    "    )\n",
    "    return (ll + np.log(log_density.shape[-1] * log_density.shape[-2])) / np.log(2)\n",
    "\n",
    "\n",
    "def nss(log_density, fixation_mask, weights=None):\n",
    "    weights = len(weights) * weights.view(-1, 1, 1) / weights.sum()\n",
    "    if isinstance(fixation_mask, torch.sparse.IntTensor):\n",
    "        dense_mask = fixation_mask.to_dense()\n",
    "    else:\n",
    "        dense_mask = fixation_mask\n",
    "\n",
    "    fixation_count = dense_mask.sum(dim=(-1, -2), keepdim=True)\n",
    "\n",
    "    density = torch.exp(log_density)\n",
    "    mean, std = torch.std_mean(density, dim=(-1, -2), keepdim=True)\n",
    "    saliency_map = (density - mean) / std\n",
    "\n",
    "    nss = torch.mean(\n",
    "        weights * torch.sum(saliency_map * dense_mask, dim=(-1, -2), keepdim=True) / fixation_count\n",
    "    )\n",
    "    return nss\n",
    "\n",
    "\n",
    "def auc(log_density, fixation_mask, weights=None):\n",
    "    weights = len(weights) * weights / weights.sum()\n",
    "\n",
    "    # TODO: This doesn't account for multiple fixations in the same location!\n",
    "    def image_auc(log_density, fixation_mask):\n",
    "        if isinstance(fixation_mask, torch.sparse.IntTensor):\n",
    "            dense_mask = fixation_mask.to_dense()\n",
    "        else:\n",
    "            dense_mask = fixation_mask\n",
    "\n",
    "        positives = torch.masked_select(log_density, dense_mask.type(torch.bool)).detach().cpu().numpy().astype(np.float64)\n",
    "        negatives = log_density.flatten().detach().cpu().numpy().astype(np.float64)\n",
    "\n",
    "        auc = _general_auc(positives, negatives)\n",
    "\n",
    "        return torch.tensor(auc)\n",
    "\n",
    "    return torch.mean(weights.cpu() * torch.tensor([\n",
    "        image_auc(log_density[i], fixation_mask[i]) for i in range(log_density.shape[0])\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "840b1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torchvision\n",
    "\n",
    "class Normalizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Normalizer, self).__init__()\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        mean = mean[:, np.newaxis, np.newaxis]\n",
    "\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        std = std[:, np.newaxis, np.newaxis]\n",
    "\n",
    "        # don't persist to keep old checkpoints working\n",
    "        self.register_buffer('mean', torch.tensor(mean), persistent=False)\n",
    "        self.register_buffer('std', torch.tensor(std), persistent=False)\n",
    "\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        tensor = tensor / 255.0\n",
    "\n",
    "        tensor -= self.mean\n",
    "        tensor /= self.std\n",
    "\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0daf9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# from .normalizer import Normalizer\n",
    "\n",
    "\n",
    "\n",
    "class RGBResNet34(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(RGBResNet34, self).__init__()\n",
    "        self.resnet = torchvision.models.resnet34(pretrained=True)\n",
    "        self.normalizer = Normalizer()\n",
    "        super(RGBResNet34, self).__init__(self.normalizer, self.resnet)\n",
    "\n",
    "\n",
    "class RGBResNet50(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(RGBResNet50, self).__init__()\n",
    "        self.resnet = torchvision.models.resnet50(pretrained=True)\n",
    "        self.normalizer = Normalizer()\n",
    "        super(RGBResNet50, self).__init__(self.normalizer, self.resnet)\n",
    "\n",
    "\n",
    "class RGBResNet50_alt(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(RGBResNet50, self).__init__()\n",
    "        self.resnet = torchvision.models.resnet50(pretrained=True)\n",
    "        self.normalizer = Normalizer()\n",
    "        state_dict = torch.load(\"Resnet-AlternativePreTrain.pth\")\n",
    "        model.load_state_dict(state_dict)\n",
    "        super(RGBResNet50, self).__init__(self.normalizer, self.resnet)\n",
    "\n",
    "\n",
    "\n",
    "class RGBResNet101(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super(RGBResNet101, self).__init__()\n",
    "        self.resnet = torchvision.models.resnet101(pretrained=True)\n",
    "        self.normalizer = Normalizer()\n",
    "        super(RGBResNet101, self).__init__(self.normalizer, self.resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a31fd166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musin\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\musin\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = RGBResNet34()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad41fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer =[ model[1].layer4[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8546ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = dict([*RGBResNet34().named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d7aca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['', '0', '1', '1.conv1', '1.bn1', '1.relu', '1.maxpool', '1.layer1', '1.layer1.0', '1.layer1.0.conv1', '1.layer1.0.bn1', '1.layer1.0.relu', '1.layer1.0.conv2', '1.layer1.0.bn2', '1.layer1.1', '1.layer1.1.conv1', '1.layer1.1.bn1', '1.layer1.1.relu', '1.layer1.1.conv2', '1.layer1.1.bn2', '1.layer1.2', '1.layer1.2.conv1', '1.layer1.2.bn1', '1.layer1.2.relu', '1.layer1.2.conv2', '1.layer1.2.bn2', '1.layer2', '1.layer2.0', '1.layer2.0.conv1', '1.layer2.0.bn1', '1.layer2.0.relu', '1.layer2.0.conv2', '1.layer2.0.bn2', '1.layer2.0.downsample', '1.layer2.0.downsample.0', '1.layer2.0.downsample.1', '1.layer2.1', '1.layer2.1.conv1', '1.layer2.1.bn1', '1.layer2.1.relu', '1.layer2.1.conv2', '1.layer2.1.bn2', '1.layer2.2', '1.layer2.2.conv1', '1.layer2.2.bn1', '1.layer2.2.relu', '1.layer2.2.conv2', '1.layer2.2.bn2', '1.layer2.3', '1.layer2.3.conv1', '1.layer2.3.bn1', '1.layer2.3.relu', '1.layer2.3.conv2', '1.layer2.3.bn2', '1.layer3', '1.layer3.0', '1.layer3.0.conv1', '1.layer3.0.bn1', '1.layer3.0.relu', '1.layer3.0.conv2', '1.layer3.0.bn2', '1.layer3.0.downsample', '1.layer3.0.downsample.0', '1.layer3.0.downsample.1', '1.layer3.1', '1.layer3.1.conv1', '1.layer3.1.bn1', '1.layer3.1.relu', '1.layer3.1.conv2', '1.layer3.1.bn2', '1.layer3.2', '1.layer3.2.conv1', '1.layer3.2.bn1', '1.layer3.2.relu', '1.layer3.2.conv2', '1.layer3.2.bn2', '1.layer3.3', '1.layer3.3.conv1', '1.layer3.3.bn1', '1.layer3.3.relu', '1.layer3.3.conv2', '1.layer3.3.bn2', '1.layer3.4', '1.layer3.4.conv1', '1.layer3.4.bn1', '1.layer3.4.relu', '1.layer3.4.conv2', '1.layer3.4.bn2', '1.layer3.5', '1.layer3.5.conv1', '1.layer3.5.bn1', '1.layer3.5.relu', '1.layer3.5.conv2', '1.layer3.5.bn2', '1.layer4', '1.layer4.0', '1.layer4.0.conv1', '1.layer4.0.bn1', '1.layer4.0.relu', '1.layer4.0.conv2', '1.layer4.0.bn2', '1.layer4.0.downsample', '1.layer4.0.downsample.0', '1.layer4.0.downsample.1', '1.layer4.1', '1.layer4.1.conv1', '1.layer4.1.bn1', '1.layer4.1.relu', '1.layer4.1.conv2', '1.layer4.1.bn2', '1.layer4.2', '1.layer4.2.conv1', '1.layer4.2.bn1', '1.layer4.2.relu', '1.layer4.2.conv2', '1.layer4.2.bn2', '1.avgpool', '1.fc'])\n"
     ]
    }
   ],
   "source": [
    "print(layers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f0ae571",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureExtractor(RGBResNet34(), ['1.layer4.2.relu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21ddfb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature = FeatureExtractor(RGBResNet34(), ['1.layer4.2.bn2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7100035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RGBResNet34(\n",
       "  (0): Normalizer()\n",
       "  (1): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f70e4951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31ba4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f964ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "        Normalizer-1          [-1, 3, 224, 224]               0\n",
      "            Conv2d-2         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-3         [-1, 64, 112, 112]             128\n",
      "              ReLU-4         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      "            Conv2d-6           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-7           [-1, 64, 56, 56]             128\n",
      "              ReLU-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 56, 56]             128\n",
      "             ReLU-11           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-12           [-1, 64, 56, 56]               0\n",
      "           Conv2d-13           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 56, 56]             128\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "           Conv2d-16           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "             ReLU-18           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-24           [-1, 64, 56, 56]             128\n",
      "             ReLU-25           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-28          [-1, 128, 28, 28]             256\n",
      "             ReLU-29          [-1, 128, 28, 28]               0\n",
      "           Conv2d-30          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-31          [-1, 128, 28, 28]             256\n",
      "           Conv2d-32          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "             ReLU-34          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-35          [-1, 128, 28, 28]               0\n",
      "           Conv2d-36          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-37          [-1, 128, 28, 28]             256\n",
      "             ReLU-38          [-1, 128, 28, 28]               0\n",
      "           Conv2d-39          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-40          [-1, 128, 28, 28]             256\n",
      "             ReLU-41          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-47          [-1, 128, 28, 28]             256\n",
      "             ReLU-48          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-49          [-1, 128, 28, 28]               0\n",
      "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-51          [-1, 128, 28, 28]             256\n",
      "             ReLU-52          [-1, 128, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-56          [-1, 128, 28, 28]               0\n",
      "           Conv2d-57          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-58          [-1, 256, 14, 14]             512\n",
      "             ReLU-59          [-1, 256, 14, 14]               0\n",
      "           Conv2d-60          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-61          [-1, 256, 14, 14]             512\n",
      "           Conv2d-62          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-63          [-1, 256, 14, 14]             512\n",
      "             ReLU-64          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-65          [-1, 256, 14, 14]               0\n",
      "           Conv2d-66          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-67          [-1, 256, 14, 14]             512\n",
      "             ReLU-68          [-1, 256, 14, 14]               0\n",
      "           Conv2d-69          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-70          [-1, 256, 14, 14]             512\n",
      "             ReLU-71          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-72          [-1, 256, 14, 14]               0\n",
      "           Conv2d-73          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-74          [-1, 256, 14, 14]             512\n",
      "             ReLU-75          [-1, 256, 14, 14]               0\n",
      "           Conv2d-76          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-77          [-1, 256, 14, 14]             512\n",
      "             ReLU-78          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-79          [-1, 256, 14, 14]               0\n",
      "           Conv2d-80          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
      "             ReLU-82          [-1, 256, 14, 14]               0\n",
      "           Conv2d-83          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-84          [-1, 256, 14, 14]             512\n",
      "             ReLU-85          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-86          [-1, 256, 14, 14]               0\n",
      "           Conv2d-87          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-88          [-1, 256, 14, 14]             512\n",
      "             ReLU-89          [-1, 256, 14, 14]               0\n",
      "           Conv2d-90          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-91          [-1, 256, 14, 14]             512\n",
      "             ReLU-92          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-98          [-1, 256, 14, 14]             512\n",
      "             ReLU-99          [-1, 256, 14, 14]               0\n",
      "      BasicBlock-100          [-1, 256, 14, 14]               0\n",
      "          Conv2d-101            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-102            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-103            [-1, 512, 7, 7]               0\n",
      "          Conv2d-104            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-105            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-106            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-108            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-109            [-1, 512, 7, 7]               0\n",
      "          Conv2d-110            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-111            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-112            [-1, 512, 7, 7]               0\n",
      "          Conv2d-113            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-115            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-116            [-1, 512, 7, 7]               0\n",
      "          Conv2d-117            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-118            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-119            [-1, 512, 7, 7]               0\n",
      "          Conv2d-120            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-121            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-122            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-123            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-124            [-1, 512, 1, 1]               0\n",
      "          Linear-125                 [-1, 1000]         513,000\n",
      "          ResNet-126                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 21,797,672\n",
      "Trainable params: 21,797,672\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 97.44\n",
      "Params size (MB): 83.15\n",
      "Estimated Total Size (MB): 181.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be110160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\"Applies Layer Normalization over a mini-batch of inputs as described in\n",
    "    the paper `Layer Normalization`_ .\n",
    "    .. math::\n",
    "        y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n",
    "    The mean and standard-deviation are calculated separately over the last\n",
    "    certain number dimensions which have to be of the shape specified by\n",
    "    :attr:`normalized_shape`.\n",
    "    :math:`\\gamma` and :math:`\\beta` are learnable affine transform parameters of\n",
    "    :attr:`normalized_shape` if :attr:`elementwise_affine` is ``True``.\n",
    "    .. note::\n",
    "        Unlike Batch Normalization and Instance Normalization, which appliesDEEPGAZE\n",
    "        \n",
    "        scalar scale and bias for each entire channel/plane with the\n",
    "        :attr:`affine` option, Layer Normalization applies per-element scale and\n",
    "        bias with :attr:`elementwise_affine`.\n",
    "    This layer uses statistics computed from input data in both training and\n",
    "    evaluation modes.\n",
    "    Args:\n",
    "        normalized_shape (int or list or torch.Size): input shape from an expected input\n",
    "            of size\n",
    "            .. math::\n",
    "                [* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n",
    "                    \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n",
    "            If a single integer is used, it is treated as a singleton list, and this module will\n",
    "            normalize over the last dimension which is expected to be of that specific size.\n",
    "        eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
    "        elementwise_affine: a boolean value that when set to ``True``, this module\n",
    "            has learnable per-element affine parameters initialized to ones (for weights)\n",
    "            and zeros (for biases). Default: ``True``.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, *)`\n",
    "        - Output: :math:`(N, *)` (same shape as input)\n",
    "    Examples::\n",
    "        >>> input = torch.randn(20, 5, 10, 10)\n",
    "        >>> # With Learnable Parameters\n",
    "        >>> m = nn.LayerNorm(input.size()[1:])\n",
    "        >>> # Without Learnable Parameters\n",
    "        >>> m = nn.LayerNorm(input.size()[1:], elementwise_affine=False)\n",
    "        >>> # Normalize over last two dimensions\n",
    "        >>> m = nn.LayerNorm([10, 10])\n",
    "        >>> # Normalize over last dimension of size 10\n",
    "        >>> m = nn.LayerNorm(10)\n",
    "        >>> # Activating the module\n",
    "        >>> output = m(input)\n",
    "    .. _`Layer Normalization`: https://arxiv.org/abs/1607.06450\n",
    "    \"\"\"\n",
    "    __constants__ = ['features', 'weight', 'bias', 'eps', 'center', 'scale']\n",
    "\n",
    "    def __init__(self, features, eps=1e-12, center=True, scale=True):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.features = features\n",
    "        self.eps = eps\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "\n",
    "        if self.scale:\n",
    "            self.weight = nn.Parameter(torch.Tensor(self.features))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "\n",
    "        if self.center:\n",
    "            self.bias = nn.Parameter(torch.Tensor(self.features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.scale:\n",
    "            nn.init.ones_(self.weight)\n",
    "\n",
    "        if self.center:\n",
    "            nn.init.zeros_(self.bias)\n",
    "\n",
    "    def adjust_parameter(self, tensor, parameter):\n",
    "        return torch.repeat_interleave(\n",
    "            torch.repeat_interleave(\n",
    "                parameter.view(-1, 1, 1),\n",
    "                repeats=tensor.shape[2],\n",
    "                dim=1),\n",
    "            repeats=tensor.shape[3],\n",
    "            dim=2\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        normalized_shape = (self.features, input.shape[2], input.shape[3])\n",
    "        weight = self.adjust_parameter(input, self.weight)\n",
    "        bias = self.adjust_parameter(input, self.bias)\n",
    "        return F.layer_norm(\n",
    "            input, normalized_shape, weight, bias, self.eps)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return '{features}, eps={eps}, ' \\\n",
    "            'center={center}, scale={scale}'.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7cd6949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_modules at 0x0000017E9FCC5CF0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d172272e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-35d44184c62a>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[24], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    ('conv0': nn.Conv2d(256, 1, (1,1), bias =False))\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class DeepGaze():\n",
    "    def __init__(self):\n",
    "        features = RGBResNet34()\n",
    "        feature_extractor = FeatureExtractor(features,[])\n",
    "        \n",
    "        readout_network = nn.Sequential(OrderedDict([\n",
    "            ('conv0': nn.Conv2d(256, 1, (1,1), bias =False))\n",
    "        ]))\n",
    "        \n",
    "        super().__init__(\n",
    "            features = feature_extractor,\n",
    "            readout_network = readout_network,\n",
    "            downsample = 2,\n",
    "            readout_factor = 4,\n",
    "            saliency_map_factor =4,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e150e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
